{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Problem Set 6\n",
    "\n",
    "Natasha Watkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "from scipy.optimize import minimize, rosen\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(x0, b, Q, ɛ=1e-5, maxiter=100):\n",
    "    \n",
    "    diff = 1e3\n",
    "    i = 0\n",
    "    x = x0\n",
    "    \n",
    "    while diff > ɛ and i < maxiter:\n",
    "        Df = Q @ x - b\n",
    "        α = np.outer(Df, Df) / (Df @ Q @ Df)\n",
    "        new_x = x - α @ Df\n",
    "        diff = norm(new_x - x)\n",
    "        x = new_x\n",
    "        i += 1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60000269, 1.99999329])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.array([[5, 0], \n",
    "              [0, 1]])\n",
    "b = np.array([3, 2])\n",
    "x = np.array([1, 1])\n",
    "c = 1\n",
    "\n",
    "steepest_descent(x, b, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -1.8999999999999995\n",
       " hess_inv: array([[2.00003922e-01, 3.44462648e-06],\n",
       "       [3.44462648e-06, 1.00002627e+00]])\n",
       "      jac: array([ 0.00000000e+00, -2.98023224e-08])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 28\n",
       "      nit: 6\n",
       "     njev: 7\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.59999999, 1.99999997])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: 0.5 * x.T @ Q @ x - b.T @ x + c\n",
    "minimize(f, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gradient(f, x, Rerr=1e-5):\n",
    "    \n",
    "    h = np.sqrt(Rerr)\n",
    "    f0 = f(x)\n",
    "    \n",
    "    if np.isscalar(x):\n",
    "        n = 1\n",
    "    else:\n",
    "        n = len(x)\n",
    "    \n",
    "    if np.isscalar(f0):\n",
    "        m = 1\n",
    "    else:\n",
    "        m = len(f0)\n",
    "        \n",
    "    Df = np.empty((m, n))\n",
    "\n",
    "    \n",
    "    for i in range(n):\n",
    "        Df[:, i] = ((f(x + h * np.eye(n)[:, i]) - f0) - (f(x - h * np.eye(n)[:, i]) - f0)) / (2 * h)\n",
    "    \n",
    "    return Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.     ,  0.     ,  1.     ],\n",
       "       [ 3.00001, -1.     ,  0.     ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: np.array([x[0] ** 2 + x[2], x[0] ** 3 - x[1]]).T\n",
    "x = np.array([1, 2, 3])\n",
    "\n",
    "find_gradient(f, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous code to compute minimum using secant method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant_method(f, x0, x1, ɛ=1e-6, max_iter=1000):\n",
    "    \n",
    "    x = np.zeros(max_iter)  # Store x's\n",
    "    x[0] = x0\n",
    "    x[1] = x1\n",
    "    f_primes = np.zeros(max_iter)  # Store f_primes\n",
    "    f_primes[0] = find_gradient(f, x0).flatten()\n",
    "    \n",
    "    diff = 1e3  # Initialise distance\n",
    "    i = 1       # Initialise iteration from 1 (x0 already calculated)\n",
    "    \n",
    "    while diff > ɛ and i < max_iter:\n",
    "        f_primes[i] = find_gradient(f, x[i]).flatten()\n",
    "        x[i+1] = x[i] - f_primes[i] * (x[i] - x[i-1])/(f_primes[i] - f_primes[i-1])  # Update x\n",
    "        diff = np.abs(x[i] - x[i-1]) / np.abs(x[i])  # Normalised difference\n",
    "        i += 1\n",
    "        \n",
    "    return x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(f, x0, ɛ=1e-5, maxiter=1000):\n",
    "    \n",
    "    diff = 1e3\n",
    "    i = 0\n",
    "    x = x0\n",
    "    \n",
    "    while diff > ɛ and i < maxiter:\n",
    "        Df = find_gradient(f, x).flatten()\n",
    "        ϕ = lambda α: f(x - α * Df.T)\n",
    "        α = secant_method(ϕ, 0.1, 0.8)\n",
    "        new_x = x - α * Df\n",
    "        diff = norm(new_x - x)\n",
    "        x = new_x\n",
    "        i += 1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(params):\n",
    "    x, y = params\n",
    "    return 100 * (y - x**2)**2 + (1 - x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9970849 , 0.99416807])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steepest_descent(f, np.array([-2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 1.8074006428375337e-11\n",
       " hess_inv: array([[0.48100066, 0.95987351],\n",
       "       [0.95987351, 1.92026229]])\n",
       "      jac: array([-9.52886349e-06,  4.99447910e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 168\n",
       "      nit: 35\n",
       "     njev: 42\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.99999575, 0.99999152])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(rosen, [-2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
